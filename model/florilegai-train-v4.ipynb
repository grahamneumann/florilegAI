{"cells":[{"metadata":{},"cell_type":"markdown","source":"Reference: https://github.com/YongWookHa/DCGAN-Keras/blob/master/main.py"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport os \nimport matplotlib.pyplot as plt\nimport cv2\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport keras\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten, Input\nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Conv2DTranspose, ZeroPadding2D, UpSampling2D\n\nimport tensorflow as tf\nprint(tf.__version__)\nprint(cv2.__version__)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def list_images(basePath, contains=None):\n    # return the set of files that are valid\n    return list_files(basePath, validExts=(\".jpg\", \".jpeg\", \".png\", \".bmp\"), contains=contains)\n\ndef list_files(basePath, validExts=(\".jpg\", \".jpeg\", \".png\", \".bmp\"), contains=None):\n    # loop over the directory structure\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        # loop over the filenames in the current directory\n        for filename in filenames:\n            # if the contains string is not none and the filename does not contain\n            # the supplied string, then ignore the file\n            if contains is not None and filename.find(contains) == -1:\n                continue\n\n            # determine the file extension of the current file\n            ext = filename[filename.rfind(\".\"):].lower()\n\n            # check to see if the file is an image and should be processed\n            if ext.endswith(validExts):\n                # construct the path to the image and yield it\n                imagePath = os.path.join(rootDir, filename).replace(\" \", \"\\\\ \")\n                yield imagePath\n                \ndef load_images(directory='', size=(128,128)):\n    images = []\n    labels = []  # Integers corresponding to the categories in alphabetical order\n    label = 0\n\n    imagePaths = list(list_images(directory))\n    \n    for path in imagePaths:\n        print(path)\n        if not('OSX' in path):\n            path = path.replace('\\\\','/')\n\n            image = cv2.imread(path) #Reading the image with OpenCV\n            image = cv2.resize(image,size) #Resizing the image, in case some are not of the same size\n\n            images.append(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    \n    return images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images=load_images('../input/floril256')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Looking at some images"},{"metadata":{"trusted":true},"cell_type":"code","source":"_,ax = plt.subplots(5,5, figsize = (8,8)) \nfor i in range(5):\n    for j in range(5):\n        ax[i,j].imshow(images[5*i+j])\n        ax[i,j].axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the GAN"},{"metadata":{"trusted":true},"cell_type":"code","source":"class GAN():\n    def __init__(self):\n\n        self.img_size = (128,128)\n        self.upsample_layers = 5\n        self.starting_filters = 64\n        self.kernel_size = 3\n        self.channels = 3\n        self.noise_size = 100\n        self.learning_rate = 0.0002\n\n        optimizer = Adam(self.learning_rate, beta_1=0.5)\n\n        self.discriminator = self.build_discriminator()\n        print(\"\\n---------------------discriminator summary----------------------------\")\n        self.discriminator.summary()        \n        self.discriminator.compile(loss='binary_crossentropy', \n                                   optimizer=optimizer,\n                                   metrics=['accuracy'])\n\n        self.generator = self.build_generator()\n        print(\"---------------------generator summary----------------------------\")\n        self.generator.summary()\n        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n        \n        self.combined = Sequential()\n        self.combined.add(self.generator)\n        self.combined.add(self.discriminator)\n        \n        self.discriminator.trainable = False\n        \n        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n        \n        self.combined.summary()\n        \n    # Creating the generator, the large kernels in the convolutional layers allow the network to create complex structures.\n    def build_generator(self):\n        \n        noise_shape = (100,)\n\n        # This block of code can be a little daunting, but essentially it automatically calculates the required starting\n        # array size that will be correctly upscaled to our desired image size.\n        #\n        # We have 5 Upsample2D layers which each double the images width and height, so we can determine the starting\n        # x size by taking (x / 2^upsample_count) So for our target image size, 256x192, we do the following:\n        # x = (192 / 2^5), y = (256 / 2^5) [x and y are reversed within the model]\n        # We also need a 3rd dimension which is chosen relatively arbitrarily, in this case it's 64.\n        model = Sequential()\n        model.add(\n            Dense(self.starting_filters * (self.img_size[0] // (2 ** self.upsample_layers))  *  (self.img_size[1] // (2 ** self.upsample_layers)),\n                  activation=\"relu\", input_shape=noise_shape))\n        model.add(Reshape(((self.img_size[0] // (2 ** self.upsample_layers)),\n                           (self.img_size[1] // (2 ** self.upsample_layers)),\n                           self.starting_filters)))\n        model.add(BatchNormalization(momentum=0.8))\n\n        model.add(UpSampling2D())  # 6x8 -> 12x16\n        model.add(Conv2D(1024, kernel_size=self.kernel_size, padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(momentum=0.8))\n\n        model.add(UpSampling2D())  # 12x16 -> 24x32\n        model.add(Conv2D(512, kernel_size=self.kernel_size, padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(momentum=0.8))\n\n        model.add(UpSampling2D())  # 24x32 -> 48x64\n        model.add(Conv2D(256, kernel_size=self.kernel_size, padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(momentum=0.8))\n\n        model.add(UpSampling2D())  # 48x64 -> 96x128\n        model.add(Conv2D(128, kernel_size=self.kernel_size, padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(momentum=0.8))\n\n        model.add(UpSampling2D())  # 96x128 -> 192x256\n        model.add(Conv2D(64, kernel_size=self.kernel_size, padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(momentum=0.8))\n\n        model.add(Conv2D(32, kernel_size=self.kernel_size, padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(momentum=0.8))\n\n        model.add(Conv2D(self.channels, kernel_size=self.kernel_size, padding=\"same\"))\n        model.add(Activation(\"tanh\"))\n\n        model.summary()\n\n        noise = Input(shape=noise_shape)\n        img = model(noise)\n\n        return Model(noise, img)\n        \n\n    def build_discriminator(self):\n\n        img_shape = (self.img_size[0], self.img_size[1], self.channels)\n\n        model = Sequential()\n\n        model.add(Conv2D(32, kernel_size=self.kernel_size, strides=2, input_shape=img_shape, padding=\"same\"))  # 128x128 -> 64x64\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n\n        model.add(Conv2D(64, kernel_size=self.kernel_size, strides=2, padding=\"same\"))  # 64x64 -> 32x32\n        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        model.add(BatchNormalization(momentum=0.8))\n\n        model.add(Conv2D(128, kernel_size=self.kernel_size, strides=2, padding=\"same\"))  # 32x32 -> 16x16\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        model.add(BatchNormalization(momentum=0.8))\n\n        model.add(Conv2D(256, kernel_size=self.kernel_size, strides=1, padding=\"same\"))  # ?\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n\n        model.add(Conv2D(512, kernel_size=self.kernel_size, strides=1, padding=\"same\"))  # ?\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n\n        model.add(Flatten())\n        model.add(Dense(1, activation='sigmoid'))\n\n        model.summary()\n\n        img = Input(shape=img_shape)\n        validity = model(img)\n\n        return Model(img, validity)\n\n    def train(self, epochs, batch_size=128, save_images=100, save_model=2000):\n\n        X_train = np.array(images)\n        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n\n        half_batch = int(batch_size / 2)\n        \n        mean_d_loss=[0,0]\n        mean_g_loss=0\n\n        for epoch in range(epochs):\n            idx = np.random.randint(0, X_train.shape[0], half_batch)\n            imgs = X_train[idx]\n\n            noise = np.random.normal(0, 1, (half_batch, self.noise_size))\n            gen_imgs = self.generator.predict(noise)\n\n            # Training the discriminator\n            \n            # The loss of the discriminator is the mean of the losses while training on authentic and fake images\n            d_loss = 0.5 * np.add(self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1))),\n                                  self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1))))\n\n            # Training the generator\n\n            noise = np.random.normal(0, 1, (batch_size, self.noise_size))\n\n            valid_y = np.array([1] * batch_size)\n            g_loss = self.combined.train_on_batch(noise, valid_y)\n            \n            mean_d_loss[0] += d_loss[0]\n            mean_d_loss[1] += d_loss[1]\n            mean_g_loss += g_loss\n            \n            # We print the losses and accuracy of the networks every 10 batches mainly to make sure the accuracy of the discriminator\n            # is not stable at around 50% or 100% (which would mean the discriminator performs not well enough or too well)\n            if epoch % 200 == 0:\n                print (\"%d [Discriminator loss: %f, acc.: %.2f%%] [Generator loss: %f]\" % (epoch, mean_d_loss[0]/200, mean_d_loss[1]/2, mean_g_loss/200))\n                mean_d_loss=[0,0]\n                mean_g_loss=0\n                \n            if epoch % save_images == 0:\n                self.save_images(epoch)\n            \n            # We save the architecture of the model, the weights and the state of the optimizer\n            # This way we can restart the training exactly where we stopped\n            if epoch % save_model == 0:\n                self.generator.save(\"generator_%d\" % epoch)\n                self.discriminator.save(\"discriminator_%d\" % epoch)\n\n    # Saving 25 generated images to have a representation of the spectrum of images created by the generator\n    def save_images(self, epoch):\n        noise = np.random.normal(0, 1, (25, self.noise_size))\n        gen_imgs = self.generator.predict(noise)\n        \n        # Rescale from [-1,1] into [0,1]\n        gen_imgs = 0.5 * gen_imgs + 0.5\n\n        fig, axs = plt.subplots(5,5, figsize = (8,8))\n\n        for i in range(5):\n            for j in range(5):\n                axs[i,j].imshow(gen_imgs[5*i+j])\n                axs[i,j].axis('off')\n\n        plt.show()\n        \n        fig.savefig(\"generated/image_%d.png\" % epoch)\n        plt.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the networks"},{"metadata":{"trusted":true},"cell_type":"code","source":"#This folder will contain the images generated during the training\n!mkdir generated","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gan=GAN()\ngan.train(epochs=40001, batch_size=24, save_images=200, save_model=5000)\n#gan.train(epochs=2, batch_size=24, save_images=1, save_model=1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}